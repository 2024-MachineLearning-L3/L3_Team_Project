{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Total sites: 950\n",
      "Total samples: 19000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the pickle files\n",
    "print(\"Loading data...\")\n",
    "with open(\"/Users/claire/Downloads/기계학습/mon_standard.pkl\", 'rb') as fi:  # Monitored 데이터 로드\n",
    "    mon_data = pickle.load(fi)\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"Total sites:\", len(mon_data))  # 사이트 개수\n",
    "total_samples = sum(len(samples) for samples in mon_data.values())\n",
    "print(\"Total samples:\", total_samples)  # 전체 샘플 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6605263157894737\n",
      "Confusion Matrix:\n",
      " [[3 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 4 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 4 0 0]\n",
      " [0 0 0 ... 0 4 0]\n",
      " [0 0 0 ... 0 1 2]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.60      0.75      0.67         4\n",
      "           2       0.80      1.00      0.89         4\n",
      "           3       0.80      1.00      0.89         4\n",
      "           4       1.00      0.75      0.86         4\n",
      "           5       1.00      0.50      0.67         4\n",
      "           6       0.67      0.50      0.57         4\n",
      "           7       0.50      0.75      0.60         4\n",
      "           8       0.75      0.75      0.75         4\n",
      "           9       0.75      0.75      0.75         4\n",
      "          10       0.50      0.25      0.33         4\n",
      "          11       0.50      0.25      0.33         4\n",
      "          12       0.33      0.25      0.29         4\n",
      "          13       0.40      0.50      0.44         4\n",
      "          14       0.67      0.50      0.57         4\n",
      "          15       0.50      0.50      0.50         4\n",
      "          16       0.60      0.75      0.67         4\n",
      "          17       0.75      0.75      0.75         4\n",
      "          18       1.00      0.75      0.86         4\n",
      "          19       0.67      0.50      0.57         4\n",
      "          20       1.00      1.00      1.00         4\n",
      "          21       0.33      0.50      0.40         4\n",
      "          22       0.67      0.50      0.57         4\n",
      "          23       0.33      0.25      0.29         4\n",
      "          24       0.00      0.00      0.00         4\n",
      "          25       0.80      1.00      0.89         4\n",
      "          26       0.40      0.50      0.44         4\n",
      "          27       0.33      0.50      0.40         4\n",
      "          28       0.40      1.00      0.57         4\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       1.00      0.75      0.86         4\n",
      "          31       0.67      0.50      0.57         4\n",
      "          32       0.50      0.50      0.50         4\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       1.00      0.25      0.40         4\n",
      "          35       0.67      1.00      0.80         4\n",
      "          36       0.67      0.50      0.57         4\n",
      "          37       0.33      0.25      0.29         4\n",
      "          38       0.17      0.25      0.20         4\n",
      "          39       0.25      0.25      0.25         4\n",
      "          40       0.33      0.25      0.29         4\n",
      "          41       0.14      0.25      0.18         4\n",
      "          42       1.00      0.75      0.86         4\n",
      "          43       1.00      1.00      1.00         4\n",
      "          44       0.57      1.00      0.73         4\n",
      "          45       0.43      0.75      0.55         4\n",
      "          46       0.67      0.50      0.57         4\n",
      "          47       0.50      0.25      0.33         4\n",
      "          48       0.43      0.75      0.55         4\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       1.00      0.50      0.67         4\n",
      "          51       1.00      1.00      1.00         4\n",
      "          52       0.75      0.75      0.75         4\n",
      "          53       0.67      1.00      0.80         4\n",
      "          54       1.00      1.00      1.00         4\n",
      "          55       1.00      0.75      0.86         4\n",
      "          56       1.00      1.00      1.00         4\n",
      "          57       1.00      1.00      1.00         4\n",
      "          58       0.75      0.75      0.75         4\n",
      "          59       0.80      1.00      0.89         4\n",
      "          60       1.00      1.00      1.00         4\n",
      "          61       0.67      0.50      0.57         4\n",
      "          62       1.00      0.75      0.86         4\n",
      "          63       0.43      0.75      0.55         4\n",
      "          64       1.00      0.25      0.40         4\n",
      "          65       0.50      0.75      0.60         4\n",
      "          66       1.00      1.00      1.00         4\n",
      "          67       1.00      1.00      1.00         4\n",
      "          68       0.60      0.75      0.67         4\n",
      "          69       0.50      0.25      0.33         4\n",
      "          70       0.80      1.00      0.89         4\n",
      "          71       0.50      0.75      0.60         4\n",
      "          72       1.00      0.75      0.86         4\n",
      "          73       1.00      0.75      0.86         4\n",
      "          74       1.00      0.50      0.67         4\n",
      "          75       0.00      0.00      0.00         4\n",
      "          76       0.67      0.50      0.57         4\n",
      "          77       0.67      1.00      0.80         4\n",
      "          78       0.60      0.75      0.67         4\n",
      "          79       0.00      0.00      0.00         4\n",
      "          80       0.80      1.00      0.89         4\n",
      "          81       0.75      0.75      0.75         4\n",
      "          82       0.67      0.50      0.57         4\n",
      "          83       0.67      1.00      0.80         4\n",
      "          84       0.75      0.75      0.75         4\n",
      "          85       0.75      0.75      0.75         4\n",
      "          86       1.00      0.75      0.86         4\n",
      "          87       1.00      1.00      1.00         4\n",
      "          88       1.00      1.00      1.00         4\n",
      "          89       0.50      0.50      0.50         4\n",
      "          90       0.80      1.00      0.89         4\n",
      "          91       1.00      1.00      1.00         4\n",
      "          92       1.00      1.00      1.00         4\n",
      "          93       0.80      1.00      0.89         4\n",
      "          94       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.66       380\n",
      "   macro avg       0.68      0.66      0.65       380\n",
      "weighted avg       0.68      0.66      0.65       380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def process_data_multi_class(data, max_monitored_labels=95):\n",
    "    X1, X2, y = [], [], []\n",
    "\n",
    "    for site_id, samples in enumerate(data.values()):\n",
    "        if site_id >= max_monitored_labels:\n",
    "            break\n",
    "        for sample in samples:\n",
    "            X1.append([abs(c) for c in sample])\n",
    "            X2.append([(1 if c > 0 else -1) * 512 for c in sample])\n",
    "            y.append(site_id)\n",
    "\n",
    "    return X1, X2, y\n",
    "\n",
    "# Monitored 데이터 처리\n",
    "X1, X2, y = process_data_multi_class(mon_data, max_monitored_labels=95)\n",
    "\n",
    "# 시간 간격 평균(mean) 계산 함수 수정\n",
    "def calculate_mean_time_intervals(X1):\n",
    "    mean_intervals = []\n",
    "    for sample in X1:\n",
    "        if len(sample) > 1:  # 두 개 이상의 패킷이 있어야 계산 가능\n",
    "            time_intervals = np.diff(sample)  # 시간 간격 계산\n",
    "            mean_intervals.append(np.mean(time_intervals))  # 평균 계산\n",
    "        else:\n",
    "            mean_intervals.append(0)  # 간격 계산 불가능한 경우 0 추가\n",
    "    return np.array(mean_intervals)\n",
    "\n",
    "def create_features(X1, X2):\n",
    "    X = []\n",
    "    for i in range(len(X1)):\n",
    "        packet_size_direction = sum(X2[i])\n",
    "        cumulative_packet_size = np.sum([abs(c) for c in X2[i]])\n",
    "        burst_lengths = len([c for c in X2[i] if c != 0])\n",
    "\n",
    "        num_incoming_packets = len([c for c in X2[i] if c > 0])\n",
    "        ratio_incoming_packets = num_incoming_packets / len(X2[i]) if len(X2[i]) > 0 else 0\n",
    "        num_outgoing_packets = len([c for c in X2[i] if c < 0])\n",
    "        total_packet_count = len(X2[i])\n",
    "\n",
    "        feature_vector = [\n",
    "            packet_size_direction,\n",
    "            np.mean(X1[i]) if len(X1[i]) > 0 else 0,\n",
    "            cumulative_packet_size,\n",
    "            burst_lengths,\n",
    "            num_incoming_packets,\n",
    "            ratio_incoming_packets,\n",
    "            num_outgoing_packets,\n",
    "            total_packet_count\n",
    "        ]\n",
    "        X.append(feature_vector)\n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "# 피처 생성\n",
    "X = create_features(X1, X2)\n",
    "\n",
    "# 시간 간격 평균 피처 추가\n",
    "mean_time_intervals = calculate_mean_time_intervals(X1)\n",
    "X = np.hstack((X, mean_time_intervals.reshape(-1, 1)))  # 새로운 피처 결합\n",
    "\n",
    "# 레이블 변환\n",
    "y = np.array(y)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Random Forest 모델 생성 및 학습 (주어진 하이퍼파라미터 사용)\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=30,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.001,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "svm_model = SVC(\n",
    "    C = 100,\n",
    "    gamma=1,\n",
    "    kernel='rbf',\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# VotingClassifier 정의\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('random_forest', rf_model),\n",
    "        ('gradient_boosting', gb_model),\n",
    "        ('svm', svm_model)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[2, 1, 2]\n",
    ")\n",
    "\n",
    "# Voting Classifier 학습\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# 평가 지표 출력\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
